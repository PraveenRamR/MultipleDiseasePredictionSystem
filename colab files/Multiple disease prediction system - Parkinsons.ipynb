{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B5Zl1UOBMAJ"
   },
   "source": [
    "Importing the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2162,
     "status": "ok",
     "timestamp": 1653200307851,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "YOCpZ1Vm6cfW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZm-USrtB_q4"
   },
   "source": [
    "Data Collection & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1653200307854,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "5YC2lGuVBiZA"
   },
   "outputs": [],
   "source": [
    "# loading the data from csv file to a Pandas DataFrame\n",
    "parkinsons_data = pd.read_csv('parkinsons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1653200307855,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "Iw8z6w60Djd2",
    "outputId": "ca177b83-79f9-46c5-89c0-42985b1923ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the first 5 rows of the dataframe\n",
    "parkinsons_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1653200307855,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "cK7L_o2TDuZb",
    "outputId": "ff4ba57f-ef7c-42e3-e76d-c6cd69e8b250"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows and columns in the dataframe\n",
    "parkinsons_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1653200307856,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "NLmzHIgnEGi4",
    "outputId": "59986869-f8e1-47a7-cd80-aa699514e488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              195 non-null    object \n",
      " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
      " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
      " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
      " 4   MDVP:Jitter(%)    195 non-null    float64\n",
      " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
      " 6   MDVP:RAP          195 non-null    float64\n",
      " 7   MDVP:PPQ          195 non-null    float64\n",
      " 8   Jitter:DDP        195 non-null    float64\n",
      " 9   MDVP:Shimmer      195 non-null    float64\n",
      " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
      " 11  Shimmer:APQ3      195 non-null    float64\n",
      " 12  Shimmer:APQ5      195 non-null    float64\n",
      " 13  MDVP:APQ          195 non-null    float64\n",
      " 14  Shimmer:DDA       195 non-null    float64\n",
      " 15  NHR               195 non-null    float64\n",
      " 16  HNR               195 non-null    float64\n",
      " 17  status            195 non-null    int64  \n",
      " 18  RPDE              195 non-null    float64\n",
      " 19  DFA               195 non-null    float64\n",
      " 20  spread1           195 non-null    float64\n",
      " 21  spread2           195 non-null    float64\n",
      " 22  D2                195 non-null    float64\n",
      " 23  PPE               195 non-null    float64\n",
      "dtypes: float64(22), int64(1), object(1)\n",
      "memory usage: 36.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# getting more information about the dataset\n",
    "parkinsons_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1653200307857,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "70rgu_k4ET9F",
    "outputId": "9d86783c-8f01-468a-a9a0-04552ebc10c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                0\n",
       "MDVP:Fo(Hz)         0\n",
       "MDVP:Fhi(Hz)        0\n",
       "MDVP:Flo(Hz)        0\n",
       "MDVP:Jitter(%)      0\n",
       "MDVP:Jitter(Abs)    0\n",
       "MDVP:RAP            0\n",
       "MDVP:PPQ            0\n",
       "Jitter:DDP          0\n",
       "MDVP:Shimmer        0\n",
       "MDVP:Shimmer(dB)    0\n",
       "Shimmer:APQ3        0\n",
       "Shimmer:APQ5        0\n",
       "MDVP:APQ            0\n",
       "Shimmer:DDA         0\n",
       "NHR                 0\n",
       "HNR                 0\n",
       "status              0\n",
       "RPDE                0\n",
       "DFA                 0\n",
       "spread1             0\n",
       "spread2             0\n",
       "D2                  0\n",
       "PPE                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values in each column\n",
    "parkinsons_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 853,
     "status": "ok",
     "timestamp": 1653200308700,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "1AxFu0-nEhSA",
    "outputId": "333d5e58-f085-43dc-ccb1-e7fc75084bcf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>154.228641</td>\n",
       "      <td>197.104918</td>\n",
       "      <td>116.324631</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>0.282251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046993</td>\n",
       "      <td>0.024847</td>\n",
       "      <td>21.885974</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.498536</td>\n",
       "      <td>0.718099</td>\n",
       "      <td>-5.684397</td>\n",
       "      <td>0.226510</td>\n",
       "      <td>2.381826</td>\n",
       "      <td>0.206552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41.390065</td>\n",
       "      <td>91.491548</td>\n",
       "      <td>43.521413</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.008903</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>0.194877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>0.040418</td>\n",
       "      <td>4.425764</td>\n",
       "      <td>0.431878</td>\n",
       "      <td>0.103942</td>\n",
       "      <td>0.055336</td>\n",
       "      <td>1.090208</td>\n",
       "      <td>0.083406</td>\n",
       "      <td>0.382799</td>\n",
       "      <td>0.090119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>88.333000</td>\n",
       "      <td>102.145000</td>\n",
       "      <td>65.476000</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>8.441000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256570</td>\n",
       "      <td>0.574282</td>\n",
       "      <td>-7.964984</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>1.423287</td>\n",
       "      <td>0.044539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.572000</td>\n",
       "      <td>134.862500</td>\n",
       "      <td>84.291000</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.016505</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>19.198000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421306</td>\n",
       "      <td>0.674758</td>\n",
       "      <td>-6.450096</td>\n",
       "      <td>0.174351</td>\n",
       "      <td>2.099125</td>\n",
       "      <td>0.137451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>148.790000</td>\n",
       "      <td>175.829000</td>\n",
       "      <td>104.315000</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>0.022970</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038360</td>\n",
       "      <td>0.011660</td>\n",
       "      <td>22.085000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.495954</td>\n",
       "      <td>0.722254</td>\n",
       "      <td>-5.720868</td>\n",
       "      <td>0.218885</td>\n",
       "      <td>2.361532</td>\n",
       "      <td>0.194052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>182.769000</td>\n",
       "      <td>224.205500</td>\n",
       "      <td>140.018500</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.037885</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060795</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>25.075500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.587562</td>\n",
       "      <td>0.761881</td>\n",
       "      <td>-5.046192</td>\n",
       "      <td>0.279234</td>\n",
       "      <td>2.636456</td>\n",
       "      <td>0.252980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>260.105000</td>\n",
       "      <td>592.030000</td>\n",
       "      <td>239.170000</td>\n",
       "      <td>0.033160</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>0.019580</td>\n",
       "      <td>0.064330</td>\n",
       "      <td>0.119080</td>\n",
       "      <td>1.302000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169420</td>\n",
       "      <td>0.314820</td>\n",
       "      <td>33.047000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685151</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-2.434031</td>\n",
       "      <td>0.450493</td>\n",
       "      <td>3.671155</td>\n",
       "      <td>0.527367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "count   195.000000    195.000000    195.000000      195.000000   \n",
       "mean    154.228641    197.104918    116.324631        0.006220   \n",
       "std      41.390065     91.491548     43.521413        0.004848   \n",
       "min      88.333000    102.145000     65.476000        0.001680   \n",
       "25%     117.572000    134.862500     84.291000        0.003460   \n",
       "50%     148.790000    175.829000    104.315000        0.004940   \n",
       "75%     182.769000    224.205500    140.018500        0.007365   \n",
       "max     260.105000    592.030000    239.170000        0.033160   \n",
       "\n",
       "       MDVP:Jitter(Abs)    MDVP:RAP    MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
       "count        195.000000  195.000000  195.000000  195.000000    195.000000   \n",
       "mean           0.000044    0.003306    0.003446    0.009920      0.029709   \n",
       "std            0.000035    0.002968    0.002759    0.008903      0.018857   \n",
       "min            0.000007    0.000680    0.000920    0.002040      0.009540   \n",
       "25%            0.000020    0.001660    0.001860    0.004985      0.016505   \n",
       "50%            0.000030    0.002500    0.002690    0.007490      0.022970   \n",
       "75%            0.000060    0.003835    0.003955    0.011505      0.037885   \n",
       "max            0.000260    0.021440    0.019580    0.064330      0.119080   \n",
       "\n",
       "       MDVP:Shimmer(dB)  ...  Shimmer:DDA         NHR         HNR      status  \\\n",
       "count        195.000000  ...   195.000000  195.000000  195.000000  195.000000   \n",
       "mean           0.282251  ...     0.046993    0.024847   21.885974    0.753846   \n",
       "std            0.194877  ...     0.030459    0.040418    4.425764    0.431878   \n",
       "min            0.085000  ...     0.013640    0.000650    8.441000    0.000000   \n",
       "25%            0.148500  ...     0.024735    0.005925   19.198000    1.000000   \n",
       "50%            0.221000  ...     0.038360    0.011660   22.085000    1.000000   \n",
       "75%            0.350000  ...     0.060795    0.025640   25.075500    1.000000   \n",
       "max            1.302000  ...     0.169420    0.314820   33.047000    1.000000   \n",
       "\n",
       "             RPDE         DFA     spread1     spread2          D2         PPE  \n",
       "count  195.000000  195.000000  195.000000  195.000000  195.000000  195.000000  \n",
       "mean     0.498536    0.718099   -5.684397    0.226510    2.381826    0.206552  \n",
       "std      0.103942    0.055336    1.090208    0.083406    0.382799    0.090119  \n",
       "min      0.256570    0.574282   -7.964984    0.006274    1.423287    0.044539  \n",
       "25%      0.421306    0.674758   -6.450096    0.174351    2.099125    0.137451  \n",
       "50%      0.495954    0.722254   -5.720868    0.218885    2.361532    0.194052  \n",
       "75%      0.587562    0.761881   -5.046192    0.279234    2.636456    0.252980  \n",
       "max      0.685151    0.825288   -2.434031    0.450493    3.671155    0.527367  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting some statistical measures about the data\n",
    "parkinsons_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1653200308701,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "3O8AclzwExyH",
    "outputId": "6a330028-c2a3-431a-f1cb-b529137cdcc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "1    147\n",
       "0     48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of target Variable\n",
    "parkinsons_data['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1srlxtEFYfN"
   },
   "source": [
    "1  --> Parkinson's Positive\n",
    "\n",
    "0 --> Healthy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1653200308702,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "zUrPan7CFTMq",
    "outputId": "9addca6f-f25f-4cde-aa11-266fbece8b9f"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert phon_R01_S07_1phon_R01_S07_2phon_R01_S07_3phon_R01_S07_4phon_R01_S07_5phon_R01_S07_6phon_R01_S10_1phon_R01_S10_2phon_R01_S10_3phon_R01_S10_4phon_R01_S10_5phon_R01_S10_6phon_R01_S13_1phon_R01_S13_2phon_R01_S13_3phon_R01_S13_4phon_R01_S13_5phon_R01_S13_6phon_R01_S17_1phon_R01_S17_2phon_R01_S17_3phon_R01_S17_4phon_R01_S17_5phon_R01_S17_6phon_R01_S42_1phon_R01_S42_2phon_R01_S42_3phon_R01_S42_4phon_R01_S42_5phon_R01_S42_6phon_R01_S43_1phon_R01_S43_2phon_R01_S43_3phon_R01_S43_4phon_R01_S43_5phon_R01_S43_6phon_R01_S49_1phon_R01_S49_2phon_R01_S49_3phon_R01_S49_4phon_R01_S49_5phon_R01_S49_6phon_R01_S50_1phon_R01_S50_2phon_R01_S50_3phon_R01_S50_4phon_R01_S50_5phon_R01_S50_6 to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[0;32m   1493\u001b[0m         how,\n\u001b[0;32m   1494\u001b[0m         axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1495\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:959\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[1;32m--> 959\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[0;32m    960\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[0;32m    961\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    962\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    963\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    964\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    966\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:657\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[0;32m    650\u001b[0m         values,\n\u001b[0;32m    651\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    655\u001b[0m     )\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_op_ndim_compat(\n\u001b[0;32m    658\u001b[0m     values,\n\u001b[0;32m    659\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    660\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    661\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    662\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    664\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:497\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m--> 497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_cython_op(\n\u001b[0;32m    498\u001b[0m     values,\n\u001b[0;32m    499\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    500\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    501\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    502\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    503\u001b[0m     result_mask\u001b[38;5;241m=\u001b[39mresult_mask,\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    505\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[1;32m--> 541\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow, values\u001b[38;5;241m.\u001b[39mdtype, is_numeric)\n\u001b[0;32m    542\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:173\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[1;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39m__signatures__:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction is not implemented for this dtype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1692\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1692\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(x)\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'phon_R01_S07_1phon_R01_S07_2phon_R01_S07_3phon_R01_S07_4phon_R01_S07_5phon_R01_S07_6phon_R01_S10_1phon_R01_S10_2phon_R01_S10_3phon_R01_S10_4phon_R01_S10_5phon_R01_S10_6phon_R01_S13_1phon_R01_S13_2phon_R01_S13_3phon_R01_S13_4phon_R01_S13_5phon_R01_S13_6phon_R01_S17_1phon_R01_S17_2phon_R01_S17_3phon_R01_S17_4phon_R01_S17_5phon_R01_S17_6phon_R01_S42_1phon_R01_S42_2phon_R01_S42_3phon_R01_S42_4phon_R01_S42_5phon_R01_S42_6phon_R01_S43_1phon_R01_S43_2phon_R01_S43_3phon_R01_S43_4phon_R01_S43_5phon_R01_S43_6phon_R01_S49_1phon_R01_S49_2phon_R01_S49_3phon_R01_S49_4phon_R01_S49_5phon_R01_S49_6phon_R01_S50_1phon_R01_S50_2phon_R01_S50_3phon_R01_S50_4phon_R01_S50_5phon_R01_S50_6'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1696\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1696\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to complex: 'phon_R01_S07_1phon_R01_S07_2phon_R01_S07_3phon_R01_S07_4phon_R01_S07_5phon_R01_S07_6phon_R01_S10_1phon_R01_S10_2phon_R01_S10_3phon_R01_S10_4phon_R01_S10_5phon_R01_S10_6phon_R01_S13_1phon_R01_S13_2phon_R01_S13_3phon_R01_S13_4phon_R01_S13_5phon_R01_S13_6phon_R01_S17_1phon_R01_S17_2phon_R01_S17_3phon_R01_S17_4phon_R01_S17_5phon_R01_S17_6phon_R01_S42_1phon_R01_S42_2phon_R01_S42_3phon_R01_S42_4phon_R01_S42_5phon_R01_S42_6phon_R01_S43_1phon_R01_S43_2phon_R01_S43_3phon_R01_S43_4phon_R01_S43_5phon_R01_S43_6phon_R01_S49_1phon_R01_S49_2phon_R01_S49_3phon_R01_S49_4phon_R01_S49_5phon_R01_S49_6phon_R01_S50_1phon_R01_S50_2phon_R01_S50_3phon_R01_S50_4phon_R01_S50_5phon_R01_S50_6'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# grouping the data bas3ed on the target variable\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m parkinsons_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1855\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1507\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1508\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1509\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1503\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[1;32m-> 1503\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[0;32m   1504\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:329\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1503\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m-> 1503\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1457\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     ser \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;66;03m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;66;03m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;66;03m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[1;32m-> 1457\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, Categorical):\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;66;03m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;66;03m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m     \u001b[38;5;66;03m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(values)\u001b[38;5;241m.\u001b[39m_from_sequence(res_values, dtype\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    996\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1012\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m   1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(res)\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1857\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11539\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11540\u001b[0m     _num_doc,\n\u001b[0;32m  11541\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11554\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11555\u001b[0m ):\n\u001b[1;32m> 11556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11196\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11203\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11159\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11160\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4670\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   4666\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4668\u001b[0m     )\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    156\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 421\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    424\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    724\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    726\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 727\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum))\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    730\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1699\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1696\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m             \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n\u001b[1;32m-> 1699\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert phon_R01_S07_1phon_R01_S07_2phon_R01_S07_3phon_R01_S07_4phon_R01_S07_5phon_R01_S07_6phon_R01_S10_1phon_R01_S10_2phon_R01_S10_3phon_R01_S10_4phon_R01_S10_5phon_R01_S10_6phon_R01_S13_1phon_R01_S13_2phon_R01_S13_3phon_R01_S13_4phon_R01_S13_5phon_R01_S13_6phon_R01_S17_1phon_R01_S17_2phon_R01_S17_3phon_R01_S17_4phon_R01_S17_5phon_R01_S17_6phon_R01_S42_1phon_R01_S42_2phon_R01_S42_3phon_R01_S42_4phon_R01_S42_5phon_R01_S42_6phon_R01_S43_1phon_R01_S43_2phon_R01_S43_3phon_R01_S43_4phon_R01_S43_5phon_R01_S43_6phon_R01_S49_1phon_R01_S49_2phon_R01_S49_3phon_R01_S49_4phon_R01_S49_5phon_R01_S49_6phon_R01_S50_1phon_R01_S50_2phon_R01_S50_3phon_R01_S50_4phon_R01_S50_5phon_R01_S50_6 to numeric"
     ]
    }
   ],
   "source": [
    "# grouping the data bas3ed on the target variable\n",
    "parkinsons_data.groupby('status').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RY6c0waGSs7"
   },
   "source": [
    "Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "We7sRYu7Gc4q"
   },
   "source": [
    "Separating the features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1653200308702,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "UAcz8jFnFuzH"
   },
   "outputs": [],
   "source": [
    "X = parkinsons_data.drop(columns=['name','status'], axis=1)\n",
    "Y = parkinsons_data['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1653200308702,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "guRof_8WG1Yn",
    "outputId": "531b55ec-5615-47e6-dde6-51295bfe8945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
      "0        119.992       157.302        74.997         0.00784   \n",
      "1        122.400       148.650       113.819         0.00968   \n",
      "2        116.682       131.111       111.555         0.01050   \n",
      "3        116.676       137.871       111.366         0.00997   \n",
      "4        116.014       141.781       110.655         0.01284   \n",
      "..           ...           ...           ...             ...   \n",
      "190      174.188       230.978        94.261         0.00459   \n",
      "191      209.516       253.017        89.488         0.00564   \n",
      "192      174.688       240.005        74.287         0.01360   \n",
      "193      198.764       396.961        74.904         0.00740   \n",
      "194      214.289       260.277        77.973         0.00567   \n",
      "\n",
      "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
      "0             0.00007   0.00370   0.00554     0.01109       0.04374   \n",
      "1             0.00008   0.00465   0.00696     0.01394       0.06134   \n",
      "2             0.00009   0.00544   0.00781     0.01633       0.05233   \n",
      "3             0.00009   0.00502   0.00698     0.01505       0.05492   \n",
      "4             0.00011   0.00655   0.00908     0.01966       0.06425   \n",
      "..                ...       ...       ...         ...           ...   \n",
      "190           0.00003   0.00263   0.00259     0.00790       0.04087   \n",
      "191           0.00003   0.00331   0.00292     0.00994       0.02751   \n",
      "192           0.00008   0.00624   0.00564     0.01873       0.02308   \n",
      "193           0.00004   0.00370   0.00390     0.01109       0.02296   \n",
      "194           0.00003   0.00295   0.00317     0.00885       0.01884   \n",
      "\n",
      "     MDVP:Shimmer(dB)  ...  MDVP:APQ  Shimmer:DDA      NHR     HNR      RPDE  \\\n",
      "0               0.426  ...   0.02971      0.06545  0.02211  21.033  0.414783   \n",
      "1               0.626  ...   0.04368      0.09403  0.01929  19.085  0.458359   \n",
      "2               0.482  ...   0.03590      0.08270  0.01309  20.651  0.429895   \n",
      "3               0.517  ...   0.03772      0.08771  0.01353  20.644  0.434969   \n",
      "4               0.584  ...   0.04465      0.10470  0.01767  19.649  0.417356   \n",
      "..                ...  ...       ...          ...      ...     ...       ...   \n",
      "190             0.405  ...   0.02745      0.07008  0.02764  19.517  0.448439   \n",
      "191             0.263  ...   0.01879      0.04812  0.01810  19.147  0.431674   \n",
      "192             0.256  ...   0.01667      0.03804  0.10715  17.883  0.407567   \n",
      "193             0.241  ...   0.01588      0.03794  0.07223  19.020  0.451221   \n",
      "194             0.190  ...   0.01373      0.03078  0.04398  21.209  0.462803   \n",
      "\n",
      "          DFA   spread1   spread2        D2       PPE  \n",
      "0    0.815285 -4.813031  0.266482  2.301442  0.284654  \n",
      "1    0.819521 -4.075192  0.335590  2.486855  0.368674  \n",
      "2    0.825288 -4.443179  0.311173  2.342259  0.332634  \n",
      "3    0.819235 -4.117501  0.334147  2.405554  0.368975  \n",
      "4    0.823484 -3.747787  0.234513  2.332180  0.410335  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "190  0.657899 -6.538586  0.121952  2.657476  0.133050  \n",
      "191  0.683244 -6.195325  0.129303  2.784312  0.168895  \n",
      "192  0.655683 -6.787197  0.158453  2.679772  0.131728  \n",
      "193  0.643956 -6.744577  0.207454  2.138608  0.123306  \n",
      "194  0.664357 -5.724056  0.190667  2.555477  0.148569  \n",
      "\n",
      "[195 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1653200308703,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "xSNrvkJoG3cY",
    "outputId": "db156ede-5d9e-4ab4-de6d-ead138a71faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "190    0\n",
      "191    0\n",
      "192    0\n",
      "193    0\n",
      "194    0\n",
      "Name: status, Length: 195, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDeqEaaHHBAS"
   },
   "source": [
    "Splitting the data to training data & Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 810,
     "status": "ok",
     "timestamp": 1653200309503,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "4c6nrCiVG6NB"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1653200309504,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "6OqUka96H35c",
    "outputId": "47eb1e86-5aa5-41f1-deb2-e02d9d2bffe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195, 22) (156, 22) (39, 22)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIOAtx35JUMg"
   },
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vigne\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vigne\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vigne\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(LSTM(10,input_shape=(None,1),activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\Users\\vigne\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "5/5 [==============================] - 2s 123ms/step - loss: 0.6146 - val_loss: 0.5280\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5281 - val_loss: 0.4908\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4837 - val_loss: 0.3967\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4247 - val_loss: 0.3908\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3918 - val_loss: 0.3612\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3505 - val_loss: 0.2988\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3084 - val_loss: 0.2447\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2811 - val_loss: 0.2093\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2423 - val_loss: 0.1954\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2168 - val_loss: 0.1706\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2011 - val_loss: 0.1475\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1923 - val_loss: 0.1419\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1849 - val_loss: 0.1382\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1806 - val_loss: 0.1364\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1763 - val_loss: 0.1308\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1734 - val_loss: 0.1261\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1724 - val_loss: 0.1261\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1693 - val_loss: 0.1281\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1673 - val_loss: 0.1283\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1652 - val_loss: 0.1259\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1635 - val_loss: 0.1253\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1618 - val_loss: 0.1280\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1594 - val_loss: 0.1261\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1598 - val_loss: 0.1239\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1564 - val_loss: 0.1282\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1553 - val_loss: 0.1249\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.1523 - val_loss: 0.1213\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1512 - val_loss: 0.1195\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1494 - val_loss: 0.1187\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1491 - val_loss: 0.1183\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1466 - val_loss: 0.1147\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.1442 - val_loss: 0.1171\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.1422 - val_loss: 0.1149\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1441 - val_loss: 0.1129\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.1418 - val_loss: 0.1180\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1382 - val_loss: 0.1078\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1390 - val_loss: 0.1077\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.1330 - val_loss: 0.1057\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1318 - val_loss: 0.1079\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1295 - val_loss: 0.1050\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1281 - val_loss: 0.1062\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.1273 - val_loss: 0.1060\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.1251 - val_loss: 0.1034\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1219 - val_loss: 0.1049\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1219 - val_loss: 0.1036\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.1179 - val_loss: 0.1023\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.1159 - val_loss: 0.1059\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1170 - val_loss: 0.1041\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1142 - val_loss: 0.1024\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1130 - val_loss: 0.1085\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1133 - val_loss: 0.1050\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1097 - val_loss: 0.1036\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1101 - val_loss: 0.1080\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1160 - val_loss: 0.1085\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1117 - val_loss: 0.1091\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1086 - val_loss: 0.1065\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1109 - val_loss: 0.1104\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1141 - val_loss: 0.1074\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1072 - val_loss: 0.1082\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1076 - val_loss: 0.1125\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1054 - val_loss: 0.1064\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1063 - val_loss: 0.1090\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1059 - val_loss: 0.1085\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1033 - val_loss: 0.1111\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1064 - val_loss: 0.1103\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1152 - val_loss: 0.1277\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1075 - val_loss: 0.1113\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1078 - val_loss: 0.1236\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.1056 - val_loss: 0.1085\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1063 - val_loss: 0.1278\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1057 - val_loss: 0.1068\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.1030 - val_loss: 0.1219\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.1081 - val_loss: 0.1080\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1085 - val_loss: 0.1268\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1137 - val_loss: 0.1074\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1167 - val_loss: 0.1112\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1135 - val_loss: 0.1288\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.1004 - val_loss: 0.1096\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1096 - val_loss: 0.1189\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1091 - val_loss: 0.1118\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 32ms/step - loss: 0.1004 - val_loss: 0.1082\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1003 - val_loss: 0.1134\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1007 - val_loss: 0.1106\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1008 - val_loss: 0.1133\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0992 - val_loss: 0.1135\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0988 - val_loss: 0.1139\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0987 - val_loss: 0.1129\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0979 - val_loss: 0.1158\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1066 - val_loss: 0.1078\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1000 - val_loss: 0.1195\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1032 - val_loss: 0.1097\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1068 - val_loss: 0.1161\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1316 - val_loss: 0.1274\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.1246 - val_loss: 0.1073\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.1107 - val_loss: 0.1363\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1144 - val_loss: 0.1079\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.1060 - val_loss: 0.1086\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1041 - val_loss: 0.1150\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.1012 - val_loss: 0.1096\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0993 - val_loss: 0.1105\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0987 - val_loss: 0.1182\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0984 - val_loss: 0.1110\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0993 - val_loss: 0.1125\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1050 - val_loss: 0.1265\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.1067 - val_loss: 0.1083\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0992 - val_loss: 0.1226\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1020 - val_loss: 0.1070\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0973 - val_loss: 0.1138\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0992 - val_loss: 0.1094\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.1023 - val_loss: 0.1093\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0994 - val_loss: 0.1166\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1016 - val_loss: 0.1065\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0956 - val_loss: 0.1157\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0959 - val_loss: 0.1098\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0965 - val_loss: 0.1122\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0943 - val_loss: 0.1104\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0944 - val_loss: 0.1128\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0948 - val_loss: 0.1103\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0941 - val_loss: 0.1133\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0948 - val_loss: 0.1127\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0954 - val_loss: 0.1129\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0929 - val_loss: 0.1194\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0939 - val_loss: 0.1161\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0925 - val_loss: 0.1122\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0910 - val_loss: 0.1130\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0909 - val_loss: 0.1123\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0916 - val_loss: 0.1112\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0900 - val_loss: 0.1185\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0936 - val_loss: 0.1096\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0938 - val_loss: 0.1191\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0948 - val_loss: 0.1050\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0956 - val_loss: 0.1269\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0924 - val_loss: 0.1061\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0951 - val_loss: 0.1216\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0978 - val_loss: 0.1082\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1001 - val_loss: 0.1135\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1008 - val_loss: 0.1134\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0946 - val_loss: 0.1094\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0927 - val_loss: 0.1185\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0919 - val_loss: 0.1095\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0927 - val_loss: 0.1148\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0920 - val_loss: 0.1087\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0929 - val_loss: 0.1111\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0942 - val_loss: 0.1072\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0905 - val_loss: 0.1086\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0911 - val_loss: 0.1118\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0898 - val_loss: 0.1091\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0917 - val_loss: 0.1130\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0896 - val_loss: 0.1158\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0900 - val_loss: 0.1091\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0882 - val_loss: 0.1095\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0903 - val_loss: 0.1051\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0904 - val_loss: 0.1102\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0869 - val_loss: 0.1096\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0872 - val_loss: 0.1124\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0869 - val_loss: 0.1090\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0883 - val_loss: 0.1129\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0881 - val_loss: 0.1065\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0869 - val_loss: 0.1189\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0928 - val_loss: 0.1020\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0892 - val_loss: 0.1276\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0945 - val_loss: 0.1024\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1012 - val_loss: 0.1209\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0957 - val_loss: 0.1137\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0864 - val_loss: 0.1056\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0891 - val_loss: 0.1158\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0856 - val_loss: 0.1003\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0900 - val_loss: 0.1060\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0866 - val_loss: 0.1072\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0866 - val_loss: 0.1064\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0840 - val_loss: 0.1145\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0875 - val_loss: 0.1041\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0843 - val_loss: 0.1149\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0882 - val_loss: 0.1001\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0879 - val_loss: 0.1226\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0891 - val_loss: 0.1047\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0913 - val_loss: 0.1151\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0958 - val_loss: 0.1141\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0987 - val_loss: 0.1236\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.1028 - val_loss: 0.1152\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0948 - val_loss: 0.1024\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0887 - val_loss: 0.1090\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0908 - val_loss: 0.1011\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0857 - val_loss: 0.1151\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0878 - val_loss: 0.1006\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0879 - val_loss: 0.1014\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0875 - val_loss: 0.1123\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0838 - val_loss: 0.1004\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0876 - val_loss: 0.1097\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0837 - val_loss: 0.1144\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0816 - val_loss: 0.1003\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0826 - val_loss: 0.1045\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0814 - val_loss: 0.1060\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0818 - val_loss: 0.1061\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0827 - val_loss: 0.1138\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0848 - val_loss: 0.1047\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0827 - val_loss: 0.1060\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0860 - val_loss: 0.1068\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0816 - val_loss: 0.1080\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0834 - val_loss: 0.1122\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=200,batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((156, 1), (39, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Lets Do the prediction and check performance metrics\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict.shape, test_predict.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vigne\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(n_estimators=100, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;AdaBoostClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">?<span>Documentation for AdaBoostClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostClassifier(n_estimators=100, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train.values.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET 1.0\n",
      "TEST  SET 0.8717948717948718\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN SET\", clf.score(X_train, Y_train))\n",
    "print(\"TEST  SET\", clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vigne\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vigne\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vigne\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vigne\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.75510204, 0.85714286, 0.71428571, 0.75      ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X, Y.values.ravel(), cv=4)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.77 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Average: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    target_names=['attack','not attack']\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2]\n",
      " [ 3 28]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "cm = confusion_matrix(Y_test, clf.predict(X_test))\n",
    "print(cm)\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71         8\n",
      "           1       0.93      0.90      0.92        31\n",
      "\n",
      "    accuracy                           0.87        39\n",
      "   macro avg       0.80      0.83      0.81        39\n",
      "weighted avg       0.88      0.87      0.87        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlR4JG4YMfOR"
   },
   "source": [
    "Building a Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1653200309507,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "w0FjSoO1MGBU",
    "outputId": "a4715754-198f-4927-9df3-e8a104a9b154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 179ms/step\n",
      "[[0.25240266]]\n",
      "The Person has Parkinsons\n"
     ]
    }
   ],
   "source": [
    "input_data = (197.07600,206.89600,192.05500,0.00289,0.00001,0.00166,0.00168,0.00498,0.01098,0.09700,0.00563,0.00680,0.00802,0.01689,0.00339,26.77500,0.422229,0.741367,-7.348300,0.177551,1.743867,0.085569)\n",
    "\n",
    "# changing input data to a numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# reshape the numpy array\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "prediction = model.predict(input_data_reshaped)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "  print(\"The Person does not have Parkinsons Disease\")\n",
    "\n",
    "else:\n",
    "  print(\"The Person has Parkinsons\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>MDVP:APQ</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>182.018</td>\n",
       "      <td>197.173</td>\n",
       "      <td>79.187</td>\n",
       "      <td>0.00842</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00506</td>\n",
       "      <td>0.00449</td>\n",
       "      <td>0.01517</td>\n",
       "      <td>0.02503</td>\n",
       "      <td>0.231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01931</td>\n",
       "      <td>0.04115</td>\n",
       "      <td>0.01813</td>\n",
       "      <td>18.784</td>\n",
       "      <td>0.589956</td>\n",
       "      <td>0.732903</td>\n",
       "      <td>-5.445140</td>\n",
       "      <td>0.142466</td>\n",
       "      <td>2.174306</td>\n",
       "      <td>0.215558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>114.238</td>\n",
       "      <td>124.393</td>\n",
       "      <td>77.022</td>\n",
       "      <td>0.00581</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>0.00316</td>\n",
       "      <td>0.00896</td>\n",
       "      <td>0.04009</td>\n",
       "      <td>0.406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04114</td>\n",
       "      <td>0.04736</td>\n",
       "      <td>0.02073</td>\n",
       "      <td>20.437</td>\n",
       "      <td>0.653139</td>\n",
       "      <td>0.694571</td>\n",
       "      <td>-5.185987</td>\n",
       "      <td>0.259229</td>\n",
       "      <td>2.151121</td>\n",
       "      <td>0.244948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>157.821</td>\n",
       "      <td>172.975</td>\n",
       "      <td>68.401</td>\n",
       "      <td>0.00358</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>0.00587</td>\n",
       "      <td>0.03716</td>\n",
       "      <td>0.307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02764</td>\n",
       "      <td>0.06185</td>\n",
       "      <td>0.00850</td>\n",
       "      <td>22.219</td>\n",
       "      <td>0.502380</td>\n",
       "      <td>0.712170</td>\n",
       "      <td>-6.251425</td>\n",
       "      <td>0.188056</td>\n",
       "      <td>2.143851</td>\n",
       "      <td>0.160812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>117.274</td>\n",
       "      <td>129.916</td>\n",
       "      <td>110.402</td>\n",
       "      <td>0.00752</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>0.00469</td>\n",
       "      <td>0.00898</td>\n",
       "      <td>0.02293</td>\n",
       "      <td>0.221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01948</td>\n",
       "      <td>0.03568</td>\n",
       "      <td>0.00681</td>\n",
       "      <td>22.817</td>\n",
       "      <td>0.530529</td>\n",
       "      <td>0.817756</td>\n",
       "      <td>-4.608260</td>\n",
       "      <td>0.290024</td>\n",
       "      <td>2.021591</td>\n",
       "      <td>0.314464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>184.055</td>\n",
       "      <td>196.537</td>\n",
       "      <td>166.977</td>\n",
       "      <td>0.00258</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00134</td>\n",
       "      <td>0.00147</td>\n",
       "      <td>0.00403</td>\n",
       "      <td>0.01463</td>\n",
       "      <td>0.132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01234</td>\n",
       "      <td>0.02226</td>\n",
       "      <td>0.00257</td>\n",
       "      <td>26.453</td>\n",
       "      <td>0.306443</td>\n",
       "      <td>0.759203</td>\n",
       "      <td>-7.044105</td>\n",
       "      <td>0.063412</td>\n",
       "      <td>2.361532</td>\n",
       "      <td>0.115730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>140.341</td>\n",
       "      <td>159.774</td>\n",
       "      <td>67.021</td>\n",
       "      <td>0.00817</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00430</td>\n",
       "      <td>0.00440</td>\n",
       "      <td>0.01289</td>\n",
       "      <td>0.03198</td>\n",
       "      <td>0.313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02428</td>\n",
       "      <td>0.05490</td>\n",
       "      <td>0.02183</td>\n",
       "      <td>19.560</td>\n",
       "      <td>0.460139</td>\n",
       "      <td>0.720908</td>\n",
       "      <td>-5.409423</td>\n",
       "      <td>0.226850</td>\n",
       "      <td>2.359973</td>\n",
       "      <td>0.226156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>125.791</td>\n",
       "      <td>140.557</td>\n",
       "      <td>96.206</td>\n",
       "      <td>0.01378</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00826</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.02478</td>\n",
       "      <td>0.04689</td>\n",
       "      <td>0.422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03908</td>\n",
       "      <td>0.07625</td>\n",
       "      <td>0.10323</td>\n",
       "      <td>15.433</td>\n",
       "      <td>0.571010</td>\n",
       "      <td>0.690892</td>\n",
       "      <td>-5.159169</td>\n",
       "      <td>0.202146</td>\n",
       "      <td>2.441612</td>\n",
       "      <td>0.260375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>120.552</td>\n",
       "      <td>131.162</td>\n",
       "      <td>113.787</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00463</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>0.01388</td>\n",
       "      <td>0.04701</td>\n",
       "      <td>0.456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03243</td>\n",
       "      <td>0.06985</td>\n",
       "      <td>0.01222</td>\n",
       "      <td>21.378</td>\n",
       "      <td>0.415564</td>\n",
       "      <td>0.825069</td>\n",
       "      <td>-4.242867</td>\n",
       "      <td>0.299111</td>\n",
       "      <td>2.187560</td>\n",
       "      <td>0.357775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>129.336</td>\n",
       "      <td>139.867</td>\n",
       "      <td>118.604</td>\n",
       "      <td>0.00490</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00165</td>\n",
       "      <td>0.00183</td>\n",
       "      <td>0.00495</td>\n",
       "      <td>0.02498</td>\n",
       "      <td>0.228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01947</td>\n",
       "      <td>0.04188</td>\n",
       "      <td>0.00484</td>\n",
       "      <td>25.429</td>\n",
       "      <td>0.420383</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>-6.836811</td>\n",
       "      <td>0.269866</td>\n",
       "      <td>2.223719</td>\n",
       "      <td>0.147491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>208.519</td>\n",
       "      <td>220.315</td>\n",
       "      <td>199.020</td>\n",
       "      <td>0.00609</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00368</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.01105</td>\n",
       "      <td>0.01761</td>\n",
       "      <td>0.155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01307</td>\n",
       "      <td>0.02855</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>22.407</td>\n",
       "      <td>0.338097</td>\n",
       "      <td>0.712466</td>\n",
       "      <td>-6.471427</td>\n",
       "      <td>0.184378</td>\n",
       "      <td>2.502336</td>\n",
       "      <td>0.136390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "123      182.018       197.173        79.187         0.00842   \n",
       "160      114.238       124.393        77.022         0.00581   \n",
       "94       157.821       172.975        68.401         0.00358   \n",
       "57       117.274       129.916       110.402         0.00752   \n",
       "41       184.055       196.537       166.977         0.00258   \n",
       "66       140.341       159.774        67.021         0.00817   \n",
       "98       125.791       140.557        96.206         0.01378   \n",
       "5        120.552       131.162       113.787         0.00968   \n",
       "53       129.336       139.867       118.604         0.00490   \n",
       "111      208.519       220.315       199.020         0.00609   \n",
       "\n",
       "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
       "123           0.00005   0.00506   0.00449     0.01517       0.02503   \n",
       "160           0.00005   0.00299   0.00316     0.00896       0.04009   \n",
       "94            0.00002   0.00196   0.00196     0.00587       0.03716   \n",
       "57            0.00006   0.00299   0.00469     0.00898       0.02293   \n",
       "41            0.00001   0.00134   0.00147     0.00403       0.01463   \n",
       "66            0.00006   0.00430   0.00440     0.01289       0.03198   \n",
       "98            0.00011   0.00826   0.00655     0.02478       0.04689   \n",
       "5             0.00008   0.00463   0.00750     0.01388       0.04701   \n",
       "53            0.00004   0.00165   0.00183     0.00495       0.02498   \n",
       "111           0.00003   0.00368   0.00339     0.01105       0.01761   \n",
       "\n",
       "     MDVP:Shimmer(dB)  ...  MDVP:APQ  Shimmer:DDA      NHR     HNR      RPDE  \\\n",
       "123             0.231  ...   0.01931      0.04115  0.01813  18.784  0.589956   \n",
       "160             0.406  ...   0.04114      0.04736  0.02073  20.437  0.653139   \n",
       "94              0.307  ...   0.02764      0.06185  0.00850  22.219  0.502380   \n",
       "57              0.221  ...   0.01948      0.03568  0.00681  22.817  0.530529   \n",
       "41              0.132  ...   0.01234      0.02226  0.00257  26.453  0.306443   \n",
       "66              0.313  ...   0.02428      0.05490  0.02183  19.560  0.460139   \n",
       "98              0.422  ...   0.03908      0.07625  0.10323  15.433  0.571010   \n",
       "5               0.456  ...   0.03243      0.06985  0.01222  21.378  0.415564   \n",
       "53              0.228  ...   0.01947      0.04188  0.00484  25.429  0.420383   \n",
       "111             0.155  ...   0.01307      0.02855  0.00830  22.407  0.338097   \n",
       "\n",
       "          DFA   spread1   spread2        D2       PPE  \n",
       "123  0.732903 -5.445140  0.142466  2.174306  0.215558  \n",
       "160  0.694571 -5.185987  0.259229  2.151121  0.244948  \n",
       "94   0.712170 -6.251425  0.188056  2.143851  0.160812  \n",
       "57   0.817756 -4.608260  0.290024  2.021591  0.314464  \n",
       "41   0.759203 -7.044105  0.063412  2.361532  0.115730  \n",
       "66   0.720908 -5.409423  0.226850  2.359973  0.226156  \n",
       "98   0.690892 -5.159169  0.202146  2.441612  0.260375  \n",
       "5    0.825069 -4.242867  0.299111  2.187560  0.357775  \n",
       "53   0.785714 -6.836811  0.269866  2.223719  0.147491  \n",
       "111  0.712466 -6.471427  0.184378  2.502336  0.136390  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123    1\n",
       "160    1\n",
       "94     1\n",
       "57     1\n",
       "41     1\n",
       "      ..\n",
       "43     0\n",
       "22     1\n",
       "72     1\n",
       "15     1\n",
       "168    0\n",
       "Name: status, Length: 156, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCHCMHpshHU4"
   },
   "source": [
    "Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1653200309507,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "cdmTOR4MhHCB"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1653200309508,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "4gN09lokhKuZ"
   },
   "outputs": [],
   "source": [
    "filename = 'parkinsons_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1653200309510,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "IKW4D5CqhP5X"
   },
   "outputs": [],
   "source": [
    "# loading the saved model\n",
    "loaded_model = pickle.load(open('parkinsons_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1653200309511,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "m8FO1U8hRVm_",
    "outputId": "079be68d-fb39-4544-9100-c6388b397091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDVP:Fo(Hz)\n",
      "MDVP:Fhi(Hz)\n",
      "MDVP:Flo(Hz)\n",
      "MDVP:Jitter(%)\n",
      "MDVP:Jitter(Abs)\n",
      "MDVP:RAP\n",
      "MDVP:PPQ\n",
      "Jitter:DDP\n",
      "MDVP:Shimmer\n",
      "MDVP:Shimmer(dB)\n",
      "Shimmer:APQ3\n",
      "Shimmer:APQ5\n",
      "MDVP:APQ\n",
      "Shimmer:DDA\n",
      "NHR\n",
      "HNR\n",
      "RPDE\n",
      "DFA\n",
      "spread1\n",
      "spread2\n",
      "D2\n",
      "PPE\n"
     ]
    }
   ],
   "source": [
    "for column in X.columns:\n",
    "  print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1653200309512,
     "user": {
      "displayName": "siddhardh selvam",
      "userId": "13966379820454708749"
     },
     "user_tz": -330
    },
    "id": "JPyuHFeDRXZU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPgH5xu9ZLOpcMFNkcpInRX",
   "collapsed_sections": [],
   "name": "Multiple disease prediction system - Parkinsons.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
